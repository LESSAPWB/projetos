{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # definindo a conversão de imagem para tensor\n",
    "trainset = datasets.MNIST('.MNIST_data/', download=True, train=True, transform=transform) # baixando o dataset de treino\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # carregando o dataset de treino\n",
    "\n",
    "valset = datasets.MNIST('.MNIST_data/', download=True, train=False, transform=transform) # baixando o dataset de validação\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # carregando o dataset de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bf425944d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa6ElEQVR4nO3df2zU9R3H8dfxoydoe6zU9loorKDIJtJlTGojII6O0k0iP7KAugSMwcGKGaLTdVNQ3NKBCTOaDv5xMBPBH4lAZMoGxZa4tRgQQpptDSXdKKEtk6R3pUhB+tkfxJsHRfged3332ucj+Sb07vvpvfl67dMvd/3W55xzAgCghw2wHgAA0D8RIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGKQ9QCX6+rq0smTJ5Wamiqfz2c9DgDAI+ec2tvblZOTowEDrn6e0+sCdPLkSeXm5lqPAQC4QU1NTRo5cuRV7+91AUpNTZV0afC0tDTjaQAAXoXDYeXm5ka+n19NwgJUUVGhl19+WS0tLcrPz9drr72myZMnX3Pdl//slpaWRoAAIIld62WUhLwJ4e2339bKlSu1evVqffrpp8rPz1dxcbFOnTqViIcDACShhARo/fr1WrJkiR599FF9+9vf1saNGzV06FD98Y9/TMTDAQCSUNwDdP78eR08eFBFRUX/f5ABA1RUVKSampor9u/s7FQ4HI7aAAB9X9wD9Nlnn+nixYvKysqKuj0rK0stLS1X7F9eXq5AIBDZeAccAPQP5j+IWlZWplAoFNmampqsRwIA9IC4vwsuIyNDAwcOVGtra9Ttra2tCgaDV+zv9/vl9/vjPQYAoJeL+xlQSkqKJk2apMrKyshtXV1dqqysVGFhYbwfDgCQpBLyc0ArV67UokWL9L3vfU+TJ0/WK6+8oo6ODj366KOJeDgAQBJKSIAWLFig//73v1q1apVaWlr0ne98R7t27brijQkAgP7L55xz1kN8VTgcViAQUCgU4koIAJCErvf7uPm74AAA/RMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgYpD1AEBvsmbNGs9rduzY4XnNoUOHPK9ZuHCh5zXBYNDzGkmqrq72vKY3/53Wr1/veQ0SjzMgAIAJAgQAMBH3AL3wwgvy+XxR2/jx4+P9MACAJJeQ14DuvPNO7dmz5/8PMoiXmgAA0RJShkGDBsX84icAoH9IyGtAR48eVU5OjsaMGaNHHnlEx48fv+q+nZ2dCofDURsAoO+Le4AKCgq0efNm7dq1Sxs2bFBjY6OmTp2q9vb2bvcvLy9XIBCIbLm5ufEeCQDQC8U9QCUlJfrxj3+siRMnqri4WB988IHa2tr0zjvvdLt/WVmZQqFQZGtqaor3SACAXijh7w4YNmyYxo0bp4aGhm7v9/v98vv9iR4DANDLJPzngM6cOaNjx44pOzs70Q8FAEgicQ/Q008/rerqav373//W3//+d82dO1cDBw7UQw89FO+HAgAksbj/E9yJEyf00EMP6fTp07r11ls1ZcoU1dbW6tZbb433QwEAkpjPOeesh/iqcDisQCCgUCiktLQ063HQz8ydO9fzmlguRurz+Tyv6UmxfFvozX+nTz75JKZ1kyZNivMk/cP1fh/nWnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImE/0I6IJls27bN85ra2toETHKln/70p57X1NXVJWASW+PGjfO8houK9k6cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEV8MGbtBf//pXz2tef/11z2tOnTrleU1vt2rVKs9rVqxYEf9BYIIzIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABBcjBb5izpw5ntfs2LHD8xqfz+d5TVZWluc199xzj+c1kjR16lTPax544AHPa8aNG+d5DfoOzoAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNcjBR9Uk1NTUzrKisrPa+J5cKiTz31lOc1v/zlLz2vGT58uOc1QE/hDAgAYIIAAQBMeA7Qvn37NHv2bOXk5Mjn82n79u1R9zvntGrVKmVnZ2vIkCEqKirS0aNH4zUvAKCP8Bygjo4O5efnq6Kiotv7161bp1dffVUbN27U/v37dfPNN6u4uFjnzp274WEBAH2H5zchlJSUqKSkpNv7nHN65ZVX9Nxzz+nBBx+UJL3xxhvKysrS9u3btXDhwhubFgDQZ8T1NaDGxka1tLSoqKgoclsgEFBBQcFV35XU2dmpcDgctQEA+r64BqilpUXSlb+7PisrK3Lf5crLyxUIBCJbbm5uPEcCAPRS5u+CKysrUygUimxNTU3WIwEAekBcAxQMBiVJra2tUbe3trZG7ruc3+9XWlpa1AYA6PviGqC8vDwFg8GonyYPh8Pav3+/CgsL4/lQAIAk5/ldcGfOnFFDQ0Pk48bGRh0+fFjp6ekaNWqUVqxYod/85je6/fbblZeXp+eff145OTmaM2dOPOcGACQ5zwE6cOCA7r///sjHK1eulCQtWrRImzdv1jPPPKOOjg49/vjjamtr05QpU7Rr1y7ddNNN8ZsaAJD0PAdo+vTpcs5d9X6fz6c1a9ZozZo1NzQYcCNOnDgR07qzZ8/GeZLuFRQUeF7DhUXR15i/Cw4A0D8RIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiUHWAwCJkJ+fH9O6ESNGeF7T1NTkec3atWs9r5k9e7bnNX6/3/MaoKdwBgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBipOiTxo0bF9O6PXv2eF4zfvx4z2s+/fRTz2t++9vfel6zZs0az2uAnsIZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggouRAl8Ry0VMV61a5XnNSy+95HnNxo0bPa+ZOXOm5zWSNGXKlJjWAV5wBgQAMEGAAAAmPAdo3759mj17tnJycuTz+bR9+/ao+xcvXiyfzxe1zZo1K17zAgD6CM8B6ujoUH5+vioqKq66z6xZs9Tc3BzZtm7dekNDAgD6Hs9vQigpKVFJScnX7uP3+xUMBmMeCgDQ9yXkNaCqqiplZmbqjjvu0LJly3T69Omr7tvZ2alwOBy1AQD6vrgHaNasWXrjjTdUWVmptWvXqrq6WiUlJbp48WK3+5eXlysQCES23NzceI8EAOiF4v5zQAsXLoz8+a677tLEiRM1duxYVVVVacaMGVfsX1ZWppUrV0Y+DofDRAgA+oGEvw17zJgxysjIUENDQ7f3+/1+paWlRW0AgL4v4QE6ceKETp8+rezs7EQ/FAAgiXj+J7gzZ85Enc00Njbq8OHDSk9PV3p6ul588UXNnz9fwWBQx44d0zPPPKPbbrtNxcXFcR0cAJDcPAfowIEDuv/++yMff/n6zaJFi7RhwwYdOXJEf/rTn9TW1qacnBzNnDlTL730kvx+f/ymBgAkPZ9zzlkP8VXhcFiBQEChUIjXg5AUvvjiC89r5s2b53nNn//8Z89r7rvvPs9rJGnv3r0xrQOk6/8+zrXgAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLuv5Ib6G8GDfL+ZTR79mzPa3bv3u15TVVVlec1QE/hDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMOFzzjnrIb4qHA4rEAgoFAopLS3NehwgIdrb2z2vmTJliuc1dXV1ntdI0sWLF2NaB0jX/32cMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMQg6wGA/iiWi4TGemFRoLfiDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSNGj1q9f73mNz+fzvGbhwoWe10hSdnZ2TOu8OnjwYI88DtCbcQYEADBBgAAAJjwFqLy8XHfffbdSU1OVmZmpOXPmqL6+Pmqfc+fOqbS0VMOHD9ctt9yi+fPnq7W1Na5DAwCSn6cAVVdXq7S0VLW1tdq9e7cuXLigmTNnqqOjI7LPk08+qffff1/vvvuuqqurdfLkSc2bNy/ugwMAkpunNyHs2rUr6uPNmzcrMzNTBw8e1LRp0xQKhfT6669ry5Yt+v73vy9J2rRpk771rW+ptrZW99xzT/wmBwAktRt6DSgUCkmS0tPTJV16Z8+FCxdUVFQU2Wf8+PEaNWqUampquv0cnZ2dCofDURsAoO+LOUBdXV1asWKF7r33Xk2YMEGS1NLSopSUFA0bNixq36ysLLW0tHT7ecrLyxUIBCJbbm5urCMBAJJIzAEqLS1VXV2d3nrrrRsaoKysTKFQKLI1NTXd0OcDACSHmH4Qdfny5dq5c6f27dunkSNHRm4PBoM6f/682traos6CWltbFQwGu/1cfr9ffr8/ljEAAEnM0xmQc07Lly/Xtm3btHfvXuXl5UXdP2nSJA0ePFiVlZWR2+rr63X8+HEVFhbGZ2IAQJ/g6QyotLRUW7Zs0Y4dO5Samhp5XScQCGjIkCEKBAJ67LHHtHLlSqWnpystLU1PPPGECgsLeQccACCKpwBt2LBBkjR9+vSo2zdt2qTFixdLkn7/+99rwIABmj9/vjo7O1VcXKw//OEPcRkWANB3eAqQc+6a+9x0002qqKhQRUVFzEMhOVRXV3te89RTT3leM2LECM9rfvCDH3heI8V2MdIvvvjC85q//OUvntdcz9ff5S7/n0WgN+FacAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAR029EBaTYrhzt8/k8r2lubva85oEHHvC8RpKWLVvmec348eM9r/nggw88r4nl2P3oRz/yvAboKZwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmfM45Zz3EV4XDYQUCAYVCIaWlpVmPgzhbu3at5zUbNmzwvKapqcnzmljF8iUUy4VFZ8yY4XnNzp07Pa+RpJSUlJjWAdL1fx/nDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSNHr1dXVeV7z61//OqbHiuXinbF8CY0YMcLzmg8//NDzmgkTJnheA9woLkYKAOjVCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXIwUABBXXIwUANCrESAAgAlPASovL9fdd9+t1NRUZWZmas6cOaqvr4/aZ/r06fL5fFHb0qVL4zo0ACD5eQpQdXW1SktLVVtbq927d+vChQuaOXOmOjo6ovZbsmSJmpubI9u6deviOjQAIPkN8rLzrl27oj7evHmzMjMzdfDgQU2bNi1y+9ChQxUMBuMzIQCgT7qh14BCoZAkKT09Per2N998UxkZGZowYYLKysp09uzZq36Ozs5OhcPhqA0A0Pd5OgP6qq6uLq1YsUL33ntv1O+df/jhhzV69Gjl5OToyJEjevbZZ1VfX6/33nuv289TXl6uF198MdYxAABJKuafA1q2bJk+/PBDffzxxxo5cuRV99u7d69mzJihhoYGjR079or7Ozs71dnZGfk4HA4rNzeXnwMCgCR1vT8HFNMZ0PLly7Vz507t27fva+MjSQUFBZJ01QD5/X75/f5YxgAAJDFPAXLO6YknntC2bdtUVVWlvLy8a645fPiwJCk7OzumAQEAfZOnAJWWlmrLli3asWOHUlNT1dLSIkkKBAIaMmSIjh07pi1btuiHP/yhhg8friNHjujJJ5/UtGnTNHHixIT8BQAAycnTa0A+n6/b2zdt2qTFixerqalJP/nJT1RXV6eOjg7l5uZq7ty5eu6556779RyuBQcAyS0hrwFdq1W5ubmqrq728ikBAP0U14IDAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJgYZD3A5ZxzkqRwOGw8CQAgFl9+//7y+/nV9LoAtbe3S5Jyc3ONJwEA3Ij29nYFAoGr3u9z10pUD+vq6tLJkyeVmpoqn88XdV84HFZubq6ampqUlpZmNKE9jsMlHIdLOA6XcBwu6Q3HwTmn9vZ25eTkaMCAq7/S0+vOgAYMGKCRI0d+7T5paWn9+gn2JY7DJRyHSzgOl3AcLrE+Dl935vMl3oQAADBBgAAAJpIqQH6/X6tXr5bf77cexRTH4RKOwyUch0s4Dpck03HodW9CAAD0D0l1BgQA6DsIEADABAECAJggQAAAE0kToIqKCn3zm9/UTTfdpIKCAn3yySfWI/W4F154QT6fL2obP3689VgJt2/fPs2ePVs5OTny+Xzavn171P3OOa1atUrZ2dkaMmSIioqKdPToUZthE+hax2Hx4sVXPD9mzZplM2yClJeX6+6771ZqaqoyMzM1Z84c1dfXR+1z7tw5lZaWavjw4brllls0f/58tba2Gk2cGNdzHKZPn37F82Hp0qVGE3cvKQL09ttva+XKlVq9erU+/fRT5efnq7i4WKdOnbIercfdeeedam5ujmwff/yx9UgJ19HRofz8fFVUVHR7/7p16/Tqq69q48aN2r9/v26++WYVFxfr3LlzPTxpYl3rOEjSrFmzop4fW7du7cEJE6+6ulqlpaWqra3V7t27deHCBc2cOVMdHR2RfZ588km9//77evfdd1VdXa2TJ09q3rx5hlPH3/UcB0lasmRJ1PNh3bp1RhNfhUsCkydPdqWlpZGPL1686HJyclx5ebnhVD1v9erVLj8/33oMU5Lctm3bIh93dXW5YDDoXn755chtbW1tzu/3u61btxpM2DMuPw7OObdo0SL34IMPmsxj5dSpU06Sq66uds5d+m8/ePBg9+6770b2+ec//+kkuZqaGqsxE+7y4+Ccc/fdd5/7+c9/bjfUdej1Z0Dnz5/XwYMHVVRUFLltwIABKioqUk1NjeFkNo4ePaqcnByNGTNGjzzyiI4fP249kqnGxka1tLREPT8CgYAKCgr65fOjqqpKmZmZuuOOO7Rs2TKdPn3aeqSECoVCkqT09HRJ0sGDB3XhwoWo58P48eM1atSoPv18uPw4fOnNN99URkaGJkyYoLKyMp09e9ZivKvqdRcjvdxnn32mixcvKisrK+r2rKws/etf/zKaykZBQYE2b96sO+64Q83NzXrxxRc1depU1dXVKTU11Xo8Ey0tLZLU7fPjy/v6i1mzZmnevHnKy8vTsWPH9Ktf/UolJSWqqanRwIEDrceLu66uLq1YsUL33nuvJkyYIOnS8yElJUXDhg2L2rcvPx+6Ow6S9PDDD2v06NHKycnRkSNH9Oyzz6q+vl7vvfee4bTRen2A8H8lJSWRP0+cOFEFBQUaPXq03nnnHT322GOGk6E3WLhwYeTPd911lyZOnKixY8eqqqpKM2bMMJwsMUpLS1VXV9cvXgf9Olc7Do8//njkz3fddZeys7M1Y8YMHTt2TGPHju3pMbvV6/8JLiMjQwMHDrziXSytra0KBoNGU/UOw4YN07hx49TQ0GA9ipkvnwM8P640ZswYZWRk9Mnnx/Lly7Vz50599NFHUb++JRgM6vz582pra4vav68+H652HLpTUFAgSb3q+dDrA5SSkqJJkyapsrIycltXV5cqKytVWFhoOJm9M2fO6NixY8rOzrYexUxeXp6CwWDU8yMcDmv//v39/vlx4sQJnT59uk89P5xzWr58ubZt26a9e/cqLy8v6v5JkyZp8ODBUc+H+vp6HT9+vE89H651HLpz+PBhSepdzwfrd0Fcj7feesv5/X63efNm949//MM9/vjjbtiwYa6lpcV6tB711FNPuaqqKtfY2Oj+9re/uaKiIpeRkeFOnTplPVpCtbe3u0OHDrlDhw45SW79+vXu0KFD7j//+Y9zzrnf/e53btiwYW7Hjh3uyJEj7sEHH3R5eXnu888/N548vr7uOLS3t7unn37a1dTUuMbGRrdnzx733e9+191+++3u3Llz1qPHzbJly1wgEHBVVVWuubk5sp09ezayz9KlS92oUaPc3r173YEDB1xhYaErLCw0nDr+rnUcGhoa3Jo1a9yBAwdcY2Oj27FjhxszZoybNm2a8eTRkiJAzjn32muvuVGjRrmUlBQ3efJkV1tbaz1Sj1uwYIHLzs52KSkpbsSIEW7BggWuoaHBeqyE++ijj5ykK7ZFixY55y69Ffv55593WVlZzu/3uxkzZrj6+nrboRPg647D2bNn3cyZM92tt97qBg8e7EaPHu2WLFnS5/4nrbu/vyS3adOmyD6ff/65+9nPfua+8Y1vuKFDh7q5c+e65uZmu6ET4FrH4fjx427atGkuPT3d+f1+d9ttt7lf/OIXLhQK2Q5+GX4dAwDARK9/DQgA0DcRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACb+Bzr004gn1UM+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader) # iterador para o dataset de treino\n",
    "imagens, etiquetas = next(dataiter) # carregando um batch de imagens e etiquetas\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r') # mostrando a primeira imagem do batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) # para verificar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) # para verificar as forma do tensor de cada etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada\n",
    "        self.linear2 = nn.Linear(128, 64) # camada interna 1\n",
    "        self.linear3 = nn.Linear(64, 10) # camada de interna 2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
    "        X = self.linear3(X) # função de ativação de camada interna 2 para a camada de saída\n",
    "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a política de atualização dos pesos\n",
    "    inicio = time() # inicia a contagem do tempo\n",
    "\n",
    "    criterio = nn.NLLLoss() # definindo o critério para calcular a perda\n",
    "    EPOCHS = 5 # numero de epochs que o algoritmo rodará\n",
    "    modelo.train() # define o modelo como mode de treino\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "\n",
    "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casa para ficarem compatíveis com a entrada da rede\n",
    "            otimizador.zero_grad() # zerando o gradiente\n",
    "\n",
    "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
    "\n",
    "            perda_instantanea.backward() # back propagation a partiur da perda\n",
    "\n",
    "            otimizador.step() #atualizando os pesos e a bias\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
    "\n",
    "        else:\n",
    "            print(f'Perda da epoch {epoch+1}: {perda_acumulada/len(trainloader)}')\n",
    "    print(f'Tempo de treino: {time()-inicio}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao (modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device)) # output do modelo em escala logarítmica\n",
    "\n",
    "            \n",
    "            ps = torch.exp(logps) # converte a saída do modelo para a escala normal(lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo acha que é a etiqueta\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if etiqueta_certa == etiqueta_pred:\n",
    "                conta_corretas += 1\n",
    "            \n",
    "    print(f'Total de imagens testadas = {conta_todas}')\n",
    "    print(f'\\nPrecisão do modelo = {conta_corretas*100/conta_todas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo() # instanciando o modelo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # definindo o dispositivo de processamento\n",
    "modelo.to(device) # colocando o modelo no dispositivo de processamento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
