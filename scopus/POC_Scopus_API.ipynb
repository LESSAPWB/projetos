{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a URL da API\n",
    "url = \"https://api.elsevier.com/content/search/scopus\"\n",
    "\n",
    "# Parâmetros para a requisição\n",
    "params = {\n",
    "    \"query\": 'TITLE-ABS-KEY ( \"marketing\" AND ( \"data-driven\" and \"data driven\" ) )',\n",
    "    \"apiKey\": \"f4b02ed7622b9888bb5b1b126d560c36\",\n",
    "    \"count\": 200,  # Definindo o número máximo de registros por página\n",
    "    \"start\": 0  # Começando a partir do primeiro registro\n",
    "}\n",
    "\n",
    "all_results = []  # Lista para armazenar todos os resultados\n",
    "\n",
    "while True:\n",
    "    # Fazendo a requisição GET\n",
    "    response = requests.get(url=url, params=params)\n",
    "\n",
    "    # Verificando se a requisição foi bem sucedida\n",
    "    if response.status_code == 200:\n",
    "        # Transformando a resposta em um objeto JSON\n",
    "        data = response.json()\n",
    "\n",
    "        try:\n",
    "            # Adicionando os resultados desta página à lista geral\n",
    "            all_results.extend(data['search-results']['entry'])\n",
    "        except KeyError:\n",
    "            # Se a chave 'entry' não estiver presente na resposta, apenas continue para a próxima iteração\n",
    "            pass\n",
    "\n",
    "        # Verificando se há mais resultados para recuperar\n",
    "        if int(data['search-results']['opensearch:itemsPerPage']) == 0:\n",
    "            # Se não houver mais resultados, interrompa o loop\n",
    "            break\n",
    "\n",
    "        # Atualizando o índice do próximo registro a ser recuperado\n",
    "        params['start'] += params['count']\n",
    "    else:\n",
    "        # print(\"Erro na requisição\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Imprimindo o número total de resultados obtidos\n",
    "# print(\"Total de resultados:\", len(all_results))\n",
    "\n",
    "df_results = pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo colunas desnecessárias\n",
    "columns = ['@_fa', \n",
    "           'link',\n",
    "           'prism:url',\n",
    "           'eid',\n",
    "           'pii',\n",
    "           'subtype',\n",
    "           'source-id',\n",
    "           'openaccess',\n",
    "           'openaccessFlag',\n",
    "           'article-number',\n",
    "           'freetoread',\n",
    "           'freetoreadLabel',\n",
    "           'prism:aggregationType',\n",
    "           'prism:issn',\n",
    "           'prism:volume',\n",
    "           'prism:issueIdentifier',\n",
    "           'prism:pageRange',\n",
    "           'prism:coverDisplayDate',\n",
    "           'prism:isbn',\n",
    "           'prism:eIssn',\n",
    "           'pubmed-id']\n",
    "\n",
    "\n",
    "df_results = df_results.drop(columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando a coluna dc:identifier - Removendo o prefixo 'SCOPUS_ID:'\n",
    "df_results['dc:identifier'] = df_results['dc:identifier'].str.replace('SCOPUS_ID:', '')\n",
    "\n",
    "# Tratando a coluna affiliation - Transformando em uma lista de strings\n",
    "# Removendo [] da coluna affiliation\n",
    "df_results['affiliation'] = df_results['affiliation'].apply(lambda x: [aff['affilname'] for aff in x][0] if isinstance(x, list) and x else None)\n",
    "\n",
    "# Filtrando para registros que são artigos\n",
    "df_results = df_results[df_results['subtypeDescription'] == 'Article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a coluna 'abstract' ao DataFrame\n",
    "\n",
    "# Função para obter o resumo com base no DOI\n",
    "def get_abstract(doi):\n",
    "    url = f\"https://api.elsevier.com/content/abstract/doi/{doi}?apiKey=78ad236d4ac36f50eb36db481f4741a1\"\n",
    "    headers = {'Accept': 'application/json'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    try:\n",
    "        abstract_content = data[\"abstracts-retrieval-response\"][\"item\"][\"bibrecord\"][\"head\"][\"abstracts\"]\n",
    "        return abstract_content\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "# Itera sobre os valores da coluna prism:doi e obtém os resumos\n",
    "df_results['abstract'] = df_results['prism:doi'].apply(get_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando dataframe como csv\n",
    "df_results.to_csv('scopus_data_driven_marketing.csv', index=False)\n",
    "df_results.to_excel('scopus_data_driven_marketing.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando llm para analisar a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessário para llm com langchain\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "# Suprimir avisos de depreciação\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Carregar variáveis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Acessar a chave da API do OpenAI\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_csv_agent(\n",
    "    ChatOpenAI(temperature=0, model=\"gpt-4o\"), #gpt-3.5-turbo-0125\n",
    "    \"scopus_data_driven_marketing.csv\",\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSure, I can help you with that. What specific test or operation would you like to perform on the dataframe `df`?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mEu falo português, sim! Como posso ajudar você hoje?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mEntendi. Como posso te ajudar com o DataFrame `df`? Se precisar de alguma análise ou manipulação específica, é só me dizer!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mOs registros do dataframe `df` contêm informações sobre artigos acadêmicos. Cada registro inclui várias colunas com detalhes específicos sobre cada artigo. Aqui está uma descrição das colunas e o que cada uma representa:\n",
      "\n",
      "1. **dc:identifier**: Um identificador único para o artigo.\n",
      "2. **dc:title**: O título do artigo.\n",
      "3. **dc:creator**: O(s) autor(es) do artigo.\n",
      "4. **prism:publicationName**: O nome da revista ou conferência onde o artigo foi publicado.\n",
      "5. **prism:coverDate**: A data de publicação do artigo.\n",
      "6. **prism:doi**: O DOI (Digital Object Identifier) do artigo.\n",
      "7. **citedby-count**: O número de vezes que o artigo foi citado por outros trabalhos.\n",
      "8. **affiliation**: A afiliação institucional dos autores.\n",
      "9. **subtypeDescription**: O tipo de publicação (por exemplo, artigo, revisão, etc.).\n",
      "10. **abstract**: Um resumo do artigo.\n",
      "\n",
      "Aqui estão os primeiros cinco registros do dataframe `df`:\n",
      "\n",
      "1. **Registro 1**:\n",
      "   - **Título**: Developing customer analytics capability in firms of different ages: Examining the complementarity of outside-in and inside-out resources\n",
      "   - **Autor(es)**: Mehrabi H.\n",
      "   - **Revista**: Industrial Marketing Management\n",
      "   - **Data de Publicação**: 2024-05-01\n",
      "   - **DOI**: 10.1016/j.indmarman.2024.04.009\n",
      "   - **Citações**: 0\n",
      "   - **Afiliação**: Kingston Business School\n",
      "   - **Tipo de Publicação**: Artigo\n",
      "   - **Resumo**: O artigo examina como a cultura de orientação ao cliente complementa a cultura orientada a dados em empresas de diferentes idades para impulsionar a capacidade de análise de clientes e, subsequentemente, o desempenho da empresa.\n",
      "\n",
      "2. **Registro 2**:\n",
      "   - **Título**: Unlocking the potential of Industrial Internet of Things (IIOT) in the age of the industrial metaverse: Business models and challenges\n",
      "   - **Autor(es)**: Endres H.\n",
      "   - **Revista**: Industrial Marketing Management\n",
      "   - **Data de Publicação**: 2024-05-01\n",
      "   - **DOI**: 10.1016/j.indmarman.2024.03.006\n",
      "   - **Citações**: 0\n",
      "   - **Afiliação**: Universität Regensburg\n",
      "   - **Tipo de Publicação**: Artigo\n",
      "   - **Resumo**: O artigo aborda os desafios de identificar modelos de negócios adequados na era do metaverso industrial, através de uma análise de conteúdo de projetos de IIoT.\n",
      "\n",
      "3. **Registro 3**:\n",
      "   - **Título**: Future applications of generative large language models: A data-driven case study on ChatGPT\n",
      "   - **Autor(es)**: Filippo C.\n",
      "   - **Revista**: Technovation\n",
      "   - **Data de Publicação**: 2024-05-01\n",
      "   - **DOI**: 10.1016/j.technovation.2024.103002\n",
      "   - **Citações**: 1\n",
      "   - **Afiliação**: Università di Pisa\n",
      "   - **Tipo de Publicação**: Artigo\n",
      "   - **Resumo**: O estudo investiga o papel evolutivo dos modelos de linguagem generativa, com um estudo de caso específico sobre o ChatGPT, utilizando um conjunto de dados de mais de 3,8 milhões de tweets.\n",
      "\n",
      "4. **Registro 4**:\n",
      "   - **Título**: Mathematical analysis of big data analytics under bipolar complex fuzzy soft information\n",
      "   - **Autor(es)**: Jan N.\n",
      "   - **Revista**: Applied Soft Computing\n",
      "   - **Data de Publicação**: 2024-05-01\n",
      "   - **DOI**: 10.1016/j.asoc.2024.111481\n",
      "   - **Citações**: 1\n",
      "   - **Afiliação**: Korea National University of Transportation\n",
      "   - **Tipo de Publicação**: Artigo\n",
      "   - **Resumo**: O artigo desenvolve novas teorias para lidar com dados complexos e não confiáveis em cenários do mundo real, integrando as teorias de Conjunto Fuzzy Complexo Bipolar e Conjunto Soft.\n",
      "\n",
      "5. **Registro 5**:\n",
      "   - **Título**: GNN-IR: Examining graph neural networks for influencer recommendations in social media marketing\n",
      "   - **Autor(es)**: Park J.\n",
      "   - **Revista**: Journal of Retailing and Consumer Services\n",
      "   - **Data de Publicação**: 2024-05-01\n",
      "   - **DOI**: 10.1016/j.jretconser.2024.103705\n",
      "   - **Citações**: 1\n",
      "   - **Afiliação**: University of Toronto\n",
      "   - **Tipo de Publicação**: Artigo\n",
      "   - **Resumo**: O artigo introduz o GNN-IR, uma rede neural gráfica para recomendação de influenciadores, baseada nas conexões entre empresas e influenciadores do YouTube.\n",
      "\n",
      "Esses registros fornecem uma visão abrangente dos tópicos de pesquisa, autores, afiliações e impacto dos artigos publicados.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCom base nos resumos dos artigos presentes no dataframe, podemos identificar algumas tendências principais de marketing data-driven:\n",
      "\n",
      "1. **Capacidade Analítica do Cliente**:\n",
      "   - O artigo \"Developing customer analytics capability in firms of different ages: Examining the complementarity of outside-in and inside-out resources\" destaca a importância da capacidade analítica do cliente para melhorar a competitividade das empresas. A cultura orientada ao cliente e a cultura orientada a dados são complementares e essenciais para impulsionar essa capacidade, especialmente em empresas mais antigas.\n",
      "\n",
      "2. **Modelos de Negócios para IIoT**:\n",
      "   - O artigo \"Unlocking the potential of Industrial Internet of Things (IIOT) in the age of the industrial metaverse: Business models and challenges\" aborda a identificação de modelos de negócios adequados para capturar valor do IIoT. A análise de mais de 2000 artigos resultou na identificação de quatro arquétipos de modelos de negócios para IIoT, fornecendo orientações práticas para gerentes de marketing industrial.\n",
      "\n",
      "3. **Aplicações de Modelos de Linguagem de Grande Escala**:\n",
      "   - O artigo \"Future applications of generative large language models: A data-driven case study on ChatGPT\" explora as aplicações emergentes de modelos de linguagem generativa, como o ChatGPT, em diversas áreas de negócios, incluindo recursos humanos, programação, mídias sociais, automação de escritório, motores de busca e educação. A análise de tarefas específicas ajuda a entender a influência potencial desses modelos em diferentes áreas de negócios.\n",
      "\n",
      "4. **Análise de Big Data com Conjuntos Fuzzy Complexos Bipolares**:\n",
      "   - O artigo \"Mathematical analysis of big data analytics under bipolar complex fuzzy soft information\" propõe uma nova abordagem para lidar com dados complexos e não confiáveis, integrando teorias de conjuntos fuzzy complexos bipolares e conjuntos soft. Essa abordagem visa melhorar a análise de big data, essencial para a tomada de decisões baseada em dados em várias indústrias.\n",
      "\n",
      "5. **Recomendações de Influenciadores com Redes Neurais de Grafos**:\n",
      "   - O artigo \"GNN-IR: Examining graph neural networks for influencer recommendations in social media marketing\" apresenta um sistema de recomendação de influenciadores baseado em redes neurais de grafos. Utilizando dados de plataformas como YouTube, o sistema sugere influenciadores para campanhas de marketing, destacando a importância de técnicas avançadas de machine learning para otimizar estratégias de marketing.\n",
      "\n",
      "Essas tendências mostram como o marketing data-driven está evoluindo para incorporar análises avançadas, modelos de negócios inovadores, aplicações de inteligência artificial e técnicas de big data para melhorar a tomada de decisões e a eficácia das campanhas de marketing.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m### Introdução\n",
      "\n",
      "Nos últimos anos, a análise de dados e a aplicação de tecnologias emergentes têm se tornado fundamentais para a competitividade e inovação nas organizações. A capacidade de análise de clientes, por exemplo, é uma área que ainda está em desenvolvimento em muitas empresas, apesar de seu potencial para melhorar o desempenho organizacional (Mehrabi, 2024). A literatura existente tem se concentrado predominantemente em fatores organizacionais internos como impulsionadores dessa capacidade, negligenciando a importância dos recursos externos e sua complementaridade com os recursos internos (Mehrabi, 2024).\n",
      "\n",
      "Além disso, a Internet das Coisas Industrial (IIoT) e o metaverso industrial emergem como áreas promissoras, mas as empresas ainda enfrentam desafios significativos na captura de valor dessas tecnologias. A identificação de modelos de negócios adequados é crucial para superar esses desafios e maximizar o valor das iniciativas de IIoT (Endres, 2024). A análise de grandes volumes de dados, por sua vez, requer abordagens matemáticas robustas para lidar com a complexidade e a incerteza dos dados, como demonstrado pela integração de conjuntos fuzzy complexos bipolares e conjuntos soft (Jan, 2024).\n",
      "\n",
      "A aplicação de modelos de linguagem de grande escala, como o ChatGPT, também está ganhando destaque, com uma ampla gama de aplicações que vão desde a assistência em programação até a geração de conteúdo criativo (Filippo, 2024). No entanto, a identificação de influenciadores adequados para campanhas de marketing em plataformas como o YouTube ainda representa um desafio significativo para muitas empresas (Park, 2024).\n",
      "\n",
      "### Lacuna\n",
      "\n",
      "Apesar dos avanços significativos em várias áreas de análise de dados e tecnologia, ainda existem lacunas importantes na literatura. Especificamente, a complementaridade entre recursos internos e externos na capacidade de análise de clientes não foi suficientemente explorada. Além disso, a identificação de modelos de negócios eficazes para o IIoT no contexto do metaverso industrial e a aplicação de abordagens matemáticas robustas para a análise de grandes volumes de dados permanecem áreas pouco investigadas. A aplicação de modelos de linguagem de grande escala em diferentes áreas de negócios e a identificação de influenciadores para campanhas de marketing também carecem de estudos mais aprofundados.\n",
      "\n",
      "### Objetivo Geral\n",
      "\n",
      "Este artigo tem como objetivo geral explorar a complementaridade entre recursos internos e externos na capacidade de análise de clientes, identificar modelos de negócios eficazes para o IIoT no contexto do metaverso industrial, aplicar abordagens matemáticas robustas para a análise de grandes volumes de dados, e investigar a aplicação de modelos de linguagem de grande escala em diferentes áreas de negócios, bem como a identificação de influenciadores para campanhas de marketing.\n",
      "\n",
      "### Referências\n",
      "\n",
      "- Mehrabi, H. (2024). Developing customer analytics capability in firms of different ages: Examining the complementarity of outside-in and inside-out resources. *Industrial Marketing Management*. https://doi.org/10.1016/j.indmarman.2024.04.009\n",
      "- Endres, H. (2024). Unlocking the potential of Industrial Internet of Things (IIOT) in the age of the industrial metaverse: Business models and challenges. *Industrial Marketing Management*. https://doi.org/10.1016/j.indmarman.2024.03.006\n",
      "- Filippo, C. (2024). Future applications of generative large language models: A data-driven case study on ChatGPT. *Technovation*. https://doi.org/10.1016/j.technovation.2024.103002\n",
      "- Jan, N. (2024). Mathematical analysis of big data analytics under bipolar complex fuzzy soft information. *Applied Soft Computing*. https://doi.org/10.1016/j.asoc.2024.111481\n",
      "- Park, J. (2024). GNN-IR: Examining graph neural networks for influencer recommendations in social media marketing. *Journal of Retailing and Consumer Services*. https://doi.org/10.1016/j.jretconser.2024.103705\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Até mais!\n"
     ]
    }
   ],
   "source": [
    "# Criando uma conversa com while\n",
    "while True:\n",
    "    input_text = input(\"Me fala alguma coisa (Se quiser sair, digite '000'): \")\n",
    "    if input_text == '000':\n",
    "        print(\"Até mais!\")\n",
    "        break\n",
    "    agent.run(input_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
